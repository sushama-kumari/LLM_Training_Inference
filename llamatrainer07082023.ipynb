{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install -q -U transformers accelerate git+https://github.com/huggingface/peft.git","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-07-08T14:56:57.494587Z","iopub.execute_input":"2023-07-08T14:56:57.494946Z","iopub.status.idle":"2023-07-08T14:57:34.395589Z","shell.execute_reply.started":"2023-07-08T14:56:57.494917Z","shell.execute_reply":"2023-07-08T14:57:34.394330Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0m","output_type":"stream"}]},{"cell_type":"code","source":"!pip install -q datasets bitsandbytes einops wandb loralib --upgrade --quiet evaluate","metadata":{"execution":{"iopub.status.busy":"2023-07-08T14:57:34.398193Z","iopub.execute_input":"2023-07-08T14:57:34.398635Z","iopub.status.idle":"2023-07-08T14:57:55.079477Z","shell.execute_reply.started":"2023-07-08T14:57:34.398597Z","shell.execute_reply":"2023-07-08T14:57:55.078017Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"#conda install -c pytorch torchvision cudatoolkit=10.1 pytorch","metadata":{"execution":{"iopub.status.busy":"2023-07-08T14:57:55.082239Z","iopub.execute_input":"2023-07-08T14:57:55.083004Z","iopub.status.idle":"2023-07-08T14:57:55.088511Z","shell.execute_reply.started":"2023-07-08T14:57:55.082950Z","shell.execute_reply":"2023-07-08T14:57:55.087076Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"import bitsandbytes as bnb","metadata":{"execution":{"iopub.status.busy":"2023-07-08T14:57:55.091773Z","iopub.execute_input":"2023-07-08T14:57:55.092713Z","iopub.status.idle":"2023-07-08T14:57:58.529307Z","shell.execute_reply.started":"2023-07-08T14:57:55.092666Z","shell.execute_reply":"2023-07-08T14:57:58.528273Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stdout","text":"\n===================================BUG REPORT===================================\nWelcome to bitsandbytes. For bug reports, please run\n\npython -m bitsandbytes\n\n and submit this information together with your error trace to: https://github.com/TimDettmers/bitsandbytes/issues\n================================================================================\nbin /opt/conda/lib/python3.10/site-packages/bitsandbytes/libbitsandbytes_cuda117_nocublaslt.so\nCUDA SETUP: CUDA runtime path found: /opt/conda/lib/libcudart.so.11.0\nCUDA SETUP: Highest compute capability among GPUs detected: 6.0\nCUDA SETUP: Detected CUDA version 117\nCUDA SETUP: Loading binary /opt/conda/lib/python3.10/site-packages/bitsandbytes/libbitsandbytes_cuda117_nocublaslt.so...\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/bitsandbytes/cuda_setup/main.py:149: UserWarning: WARNING: The following directories listed in your path were found to be non-existent: {PosixPath('/usr/local/cuda/lib'), PosixPath('/usr/local/lib/x86_64-linux-gnu'), PosixPath('/usr/local/nvidia/lib')}\n  warn(msg)\n/opt/conda/lib/python3.10/site-packages/bitsandbytes/cuda_setup/main.py:149: UserWarning: WARNING: Compute capability < 7.5 detected! Only slow 8-bit matmul is supported for your GPU!\n  warn(msg)\n","output_type":"stream"}]},{"cell_type":"code","source":"from datasets import load_dataset","metadata":{"execution":{"iopub.status.busy":"2023-07-08T14:57:58.530861Z","iopub.execute_input":"2023-07-08T14:57:58.531889Z","iopub.status.idle":"2023-07-08T14:57:59.455658Z","shell.execute_reply.started":"2023-07-08T14:57:58.531847Z","shell.execute_reply":"2023-07-08T14:57:59.454680Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"import torch\nimport torch.nn as neuralNetwork","metadata":{"execution":{"iopub.status.busy":"2023-07-08T14:57:59.458133Z","iopub.execute_input":"2023-07-08T14:57:59.459119Z","iopub.status.idle":"2023-07-08T14:57:59.464875Z","shell.execute_reply.started":"2023-07-08T14:57:59.459067Z","shell.execute_reply":"2023-07-08T14:57:59.463686Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"import transformers \nfrom transformers import LlamaForCausalLM, LlamaTokenizer, BitsAndBytesConfig","metadata":{"execution":{"iopub.status.busy":"2023-07-08T14:57:59.466635Z","iopub.execute_input":"2023-07-08T14:57:59.467422Z","iopub.status.idle":"2023-07-08T14:58:07.449283Z","shell.execute_reply.started":"2023-07-08T14:57:59.467387Z","shell.execute_reply":"2023-07-08T14:58:07.446181Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py:98: UserWarning: unable to load libtensorflow_io_plugins.so: unable to open file: libtensorflow_io_plugins.so, from paths: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so']\ncaused by: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so: undefined symbol: _ZN3tsl6StatusC1EN10tensorflow5error4CodeESt17basic_string_viewIcSt11char_traitsIcEENS_14SourceLocationE']\n  warnings.warn(f\"unable to load libtensorflow_io_plugins.so: {e}\")\n/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py:104: UserWarning: file system plugins are not loaded: unable to open file: libtensorflow_io.so, from paths: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io.so']\ncaused by: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io.so: undefined symbol: _ZTVN10tensorflow13GcsFileSystemE']\n  warnings.warn(f\"file system plugins are not loaded: {e}\")\n","output_type":"stream"}]},{"cell_type":"code","source":"!pip install peft","metadata":{"execution":{"iopub.status.busy":"2023-07-08T14:58:07.450602Z","iopub.execute_input":"2023-07-08T14:58:07.450949Z","iopub.status.idle":"2023-07-08T14:58:19.115797Z","shell.execute_reply.started":"2023-07-08T14:58:07.450917Z","shell.execute_reply":"2023-07-08T14:58:19.114451Z"},"trusted":true},"execution_count":8,"outputs":[{"name":"stdout","text":"Requirement already satisfied: peft in /opt/conda/lib/python3.10/site-packages (0.4.0.dev0)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from peft) (1.23.5)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from peft) (21.3)\nRequirement already satisfied: psutil in /opt/conda/lib/python3.10/site-packages (from peft) (5.9.3)\nRequirement already satisfied: pyyaml in /opt/conda/lib/python3.10/site-packages (from peft) (5.4.1)\nRequirement already satisfied: torch>=1.13.0 in /opt/conda/lib/python3.10/site-packages (from peft) (2.0.0)\nRequirement already satisfied: transformers in /opt/conda/lib/python3.10/site-packages (from peft) (4.30.2)\nRequirement already satisfied: accelerate in /opt/conda/lib/python3.10/site-packages (from peft) (0.20.3)\nRequirement already satisfied: safetensors in /opt/conda/lib/python3.10/site-packages (from peft) (0.3.1)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->peft) (3.0.9)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch>=1.13.0->peft) (3.12.0)\nRequirement already satisfied: typing-extensions in /opt/conda/lib/python3.10/site-packages (from torch>=1.13.0->peft) (4.5.0)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.13.0->peft) (1.12)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.13.0->peft) (3.1)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.13.0->peft) (3.1.2)\nRequirement already satisfied: huggingface-hub<1.0,>=0.14.1 in /opt/conda/lib/python3.10/site-packages (from transformers->peft) (0.15.1)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers->peft) (2023.5.5)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from transformers->peft) (2.28.2)\nRequirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /opt/conda/lib/python3.10/site-packages (from transformers->peft) (0.13.3)\nRequirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.10/site-packages (from transformers->peft) (4.64.1)\nRequirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.14.1->transformers->peft) (2023.6.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.13.0->peft) (2.1.2)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->transformers->peft) (2.1.1)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->transformers->peft) (3.4)\nRequirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->transformers->peft) (1.26.15)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->transformers->peft) (2023.5.7)\nRequirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.13.0->peft) (1.3.0)\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0m","output_type":"stream"}]},{"cell_type":"code","source":"from peft import (\n    #prepare_model_for_kbit_training,\n    prepare_model_for_int8_training,\n    LoraConfig,\n    get_peft_model,\n)","metadata":{"execution":{"iopub.status.busy":"2023-07-08T14:58:19.118017Z","iopub.execute_input":"2023-07-08T14:58:19.118430Z","iopub.status.idle":"2023-07-08T14:58:19.141991Z","shell.execute_reply.started":"2023-07-08T14:58:19.118389Z","shell.execute_reply":"2023-07-08T14:58:19.141144Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"RANDOM_SEED = 42\ntransformers.set_seed(RANDOM_SEED)\nCUTOFF_LEN = 700\nOUTPUT_DIR = '/kaggle/working/'","metadata":{"execution":{"iopub.status.busy":"2023-07-08T14:58:19.146807Z","iopub.execute_input":"2023-07-08T14:58:19.147090Z","iopub.status.idle":"2023-07-08T14:58:19.158510Z","shell.execute_reply.started":"2023-07-08T14:58:19.147066Z","shell.execute_reply":"2023-07-08T14:58:19.157529Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"loraConfig = LoraConfig(\n    r=8,\n    lora_alpha=16, \n    target_modules=['q_proj','v_proj', 'o_proj', 'k_proj'], \n    lora_dropout=0.05,\n    bias='none', \n    task_type='CAUSAL_LM',\n)","metadata":{"execution":{"iopub.status.busy":"2023-07-08T14:58:19.160017Z","iopub.execute_input":"2023-07-08T14:58:19.160363Z","iopub.status.idle":"2023-07-08T14:58:19.165712Z","shell.execute_reply.started":"2023-07-08T14:58:19.160332Z","shell.execute_reply":"2023-07-08T14:58:19.164777Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"bnbConfig = BitsAndBytesConfig(\n    load_in_4bit=True, # <<< used to enable 4-bit quantization by replacing the Linear layers with FP4/NF4 layers.\n    bnb_4bit_use_double_quant=True, # <<< Enable double quantization = to 4bit, since normal quantization is 8bit.\n    bnb_4bit_quant_type=\"nf4\", # <<< The type of quantization which is nf4 or fp4\n    bnb_4bit_compute_dtype=torch.float16 # <<< The computation type, Note: bfloat is for A100 gpu and above.\n)","metadata":{"execution":{"iopub.status.busy":"2023-07-08T14:58:19.166893Z","iopub.execute_input":"2023-07-08T14:58:19.167951Z","iopub.status.idle":"2023-07-08T14:58:19.176587Z","shell.execute_reply.started":"2023-07-08T14:58:19.167919Z","shell.execute_reply":"2023-07-08T14:58:19.175692Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"!pip install --upgrade accelerate","metadata":{"execution":{"iopub.status.busy":"2023-07-08T14:58:19.177852Z","iopub.execute_input":"2023-07-08T14:58:19.178383Z","iopub.status.idle":"2023-07-08T14:58:30.237259Z","shell.execute_reply.started":"2023-07-08T14:58:19.178351Z","shell.execute_reply":"2023-07-08T14:58:30.236059Z"},"trusted":true},"execution_count":13,"outputs":[{"name":"stdout","text":"Requirement already satisfied: accelerate in /opt/conda/lib/python3.10/site-packages (0.20.3)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from accelerate) (1.23.5)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from accelerate) (21.3)\nRequirement already satisfied: psutil in /opt/conda/lib/python3.10/site-packages (from accelerate) (5.9.3)\nRequirement already satisfied: pyyaml in /opt/conda/lib/python3.10/site-packages (from accelerate) (5.4.1)\nRequirement already satisfied: torch>=1.6.0 in /opt/conda/lib/python3.10/site-packages (from accelerate) (2.0.0)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->accelerate) (3.0.9)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch>=1.6.0->accelerate) (3.12.0)\nRequirement already satisfied: typing-extensions in /opt/conda/lib/python3.10/site-packages (from torch>=1.6.0->accelerate) (4.5.0)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.6.0->accelerate) (1.12)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.6.0->accelerate) (3.1)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.6.0->accelerate) (3.1.2)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.6.0->accelerate) (2.1.2)\nRequirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.6.0->accelerate) (1.3.0)\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0m","output_type":"stream"}]},{"cell_type":"code","source":"model = LlamaForCausalLM.from_pretrained('huggyllama/llama-7b',\n                                         load_in_4bit=True,\n                                         torch_dtype=torch.bfloat16, #torch.float16, \n                                         quantization_config=bnbConfig,\n                                         device_map=\"auto\")","metadata":{"execution":{"iopub.status.busy":"2023-07-08T14:58:30.239542Z","iopub.execute_input":"2023-07-08T14:58:30.239940Z","iopub.status.idle":"2023-07-08T15:13:25.080062Z","shell.execute_reply.started":"2023-07-08T14:58:30.239904Z","shell.execute_reply":"2023-07-08T15:13:25.079153Z"},"trusted":true},"execution_count":14,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading (…)lve/main/config.json:   0%|          | 0.00/594 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3dcaedd2de424980920afb0482fee1d6"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)fetensors.index.json:   0%|          | 0.00/26.8k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d2db633e87884799a039be720fa491c7"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading shards:   0%|          | 0/2 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8a6762da08124dd99fd285904c8e5fd2"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)of-00002.safetensors:   0%|          | 0.00/9.98G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"cee142bc887d4828a655b9ff2254fe54"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)of-00002.safetensors:   0%|          | 0.00/3.50G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f6bcdad898ca407c88f1a864bc7a0b1b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d5741a6dfafc48b899806873816552d3"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)neration_config.json:   0%|          | 0.00/137 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"06e601d2055340a79d8d013e843dbb11"}},"metadata":{}}]},{"cell_type":"code","source":"model.gradient_checkpointing_enable()","metadata":{"execution":{"iopub.status.busy":"2023-07-08T15:15:42.343663Z","iopub.execute_input":"2023-07-08T15:15:42.344160Z","iopub.status.idle":"2023-07-08T15:15:42.357015Z","shell.execute_reply.started":"2023-07-08T15:15:42.344101Z","shell.execute_reply":"2023-07-08T15:15:42.356060Z"},"trusted":true},"execution_count":26,"outputs":[]},{"cell_type":"code","source":"model = prepare_model_for_int8_training(model)","metadata":{"execution":{"iopub.status.busy":"2023-07-08T15:15:45.678883Z","iopub.execute_input":"2023-07-08T15:15:45.679297Z","iopub.status.idle":"2023-07-08T15:15:45.702084Z","shell.execute_reply.started":"2023-07-08T15:15:45.679252Z","shell.execute_reply":"2023-07-08T15:15:45.700931Z"},"trusted":true},"execution_count":27,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/peft/utils/other.py:102: FutureWarning: prepare_model_for_int8_training is deprecated and will be removed in a future version. Use prepare_model_for_kbit_training instead.\n  warnings.warn(\n","output_type":"stream"}]},{"cell_type":"code","source":"model = get_peft_model(model, loraConfig)","metadata":{"execution":{"iopub.status.busy":"2023-07-08T15:15:51.699087Z","iopub.execute_input":"2023-07-08T15:15:51.699484Z","iopub.status.idle":"2023-07-08T15:15:51.880891Z","shell.execute_reply.started":"2023-07-08T15:15:51.699456Z","shell.execute_reply":"2023-07-08T15:15:51.879864Z"},"trusted":true},"execution_count":28,"outputs":[]},{"cell_type":"code","source":"import wandb\nfrom kaggle_secrets import UserSecretsClient\nuser_secrets = UserSecretsClient()","metadata":{"execution":{"iopub.status.busy":"2023-07-08T15:15:58.098879Z","iopub.execute_input":"2023-07-08T15:15:58.099271Z","iopub.status.idle":"2023-07-08T15:15:58.104471Z","shell.execute_reply.started":"2023-07-08T15:15:58.099239Z","shell.execute_reply":"2023-07-08T15:15:58.103429Z"},"trusted":true},"execution_count":29,"outputs":[]},{"cell_type":"code","source":"wandb_key = user_secrets.get_secret(\"wandb_api_key\")\n#(\"f9d1692baeae771a099538946b1c7cf9e40b6db5\")\nwandb.login(key=wandb_key) ","metadata":{"execution":{"iopub.status.busy":"2023-07-08T15:16:01.902841Z","iopub.execute_input":"2023-07-08T15:16:01.903231Z","iopub.status.idle":"2023-07-08T15:16:02.653975Z","shell.execute_reply.started":"2023-07-08T15:16:01.903200Z","shell.execute_reply":"2023-07-08T15:16:02.653048Z"},"trusted":true},"execution_count":30,"outputs":[{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mjaiswaldelhi1\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n","output_type":"stream"},{"execution_count":30,"output_type":"execute_result","data":{"text/plain":"True"},"metadata":{}}]},{"cell_type":"code","source":"hf_key = user_secrets.get_secret(\"huggingFaceToken\") # <<< huggingface key saved here.","metadata":{"execution":{"iopub.status.busy":"2023-07-08T15:16:05.567011Z","iopub.execute_input":"2023-07-08T15:16:05.567399Z","iopub.status.idle":"2023-07-08T15:16:05.915772Z","shell.execute_reply.started":"2023-07-08T15:16:05.567368Z","shell.execute_reply":"2023-07-08T15:16:05.914809Z"},"trusted":true},"execution_count":31,"outputs":[]},{"cell_type":"code","source":"dataset = load_dataset(\"0sunfire0/QA-Treasuries-539\")","metadata":{"execution":{"iopub.status.busy":"2023-07-08T15:16:08.395289Z","iopub.execute_input":"2023-07-08T15:16:08.395840Z","iopub.status.idle":"2023-07-08T15:16:10.308696Z","shell.execute_reply.started":"2023-07-08T15:16:08.395798Z","shell.execute_reply":"2023-07-08T15:16:10.307780Z"},"trusted":true},"execution_count":32,"outputs":[{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9539623893a14045962835462ff591d6"}},"metadata":{}}]},{"cell_type":"code","source":"def generate_prompt(data_point):\n    return f\"\"\"Below is an instruction that describes a task. Write a response in detail that appropriately completes the request.\n\n### Instruction:\n{data_point[\"Questions\"]}\n\n### Response:\n{data_point[\"Answers\"]}\"\"\"\n","metadata":{"execution":{"iopub.status.busy":"2023-07-08T15:16:23.219230Z","iopub.execute_input":"2023-07-08T15:16:23.219599Z","iopub.status.idle":"2023-07-08T15:16:23.225578Z","shell.execute_reply.started":"2023-07-08T15:16:23.219569Z","shell.execute_reply":"2023-07-08T15:16:23.223324Z"},"trusted":true},"execution_count":33,"outputs":[]},{"cell_type":"code","source":"tokenizer = LlamaTokenizer.from_pretrained('huggyllama/llama-7b')\ntokenizer.pad_token_id = 1","metadata":{"execution":{"iopub.status.busy":"2023-07-08T15:16:26.258975Z","iopub.execute_input":"2023-07-08T15:16:26.259911Z","iopub.status.idle":"2023-07-08T15:16:26.542694Z","shell.execute_reply.started":"2023-07-08T15:16:26.259876Z","shell.execute_reply":"2023-07-08T15:16:26.541010Z"},"trusted":true},"execution_count":34,"outputs":[]},{"cell_type":"code","source":"dataset = dataset.shuffle().map(\n    lambda data_point: tokenizer(\n        generate_prompt(data_point),\n        truncation=True, # <<< Enable the max_length parameter below.\n        max_length=CUTOFF_LEN, # <<< The max sequence length the tokenizer can use (was defind above to 256)\n        padding=\"max_length\", # <<< The max padding the tokenizer can use.\n    )\n)","metadata":{"execution":{"iopub.status.busy":"2023-07-08T15:17:22.891490Z","iopub.execute_input":"2023-07-08T15:17:22.891850Z","iopub.status.idle":"2023-07-08T15:17:26.227653Z","shell.execute_reply.started":"2023-07-08T15:17:22.891822Z","shell.execute_reply":"2023-07-08T15:17:26.226276Z"},"trusted":true},"execution_count":38,"outputs":[{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/539 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}}]},{"cell_type":"code","source":"trainer = transformers.Trainer(\n    model=model, # <<< Use the pretrained model we loaded earlier.\n    train_dataset=dataset[\"train\"], # <<< Use the dataset we loaded earlier.\n    tokenizer=tokenizer, # <<< Use the pretrained tokenizerwe loaded earlier.\n    args=transformers.TrainingArguments(\n        seed=RANDOM_SEED, # <<< Random seed that will be set at the beginning of training, was defined earlier.\n        data_seed=RANDOM_SEED, # <<< Random seed to be used with data samplers. \n        fp16=True, # <<< Use fp16 16-bit (mixed) precision training instead of 32-bit(for A100 gpu use bf16 instead).\n        #bf16=True,\n        output_dir=OUTPUT_DIR, # <<< Output directory where the model weights will be saved also the check points.\n        num_train_epochs=17, # Number of training epochs(better than using steps only since it run on all the data)\n        warmup_ratio=0.05, # <<<  Ratio of total training steps used for a linear warmup from 0 to learning_rate.\n        auto_find_batch_size=True, # <<< Find the optimal batch size default is 8, it works well on free gpu, (For higher gpu define per_device_train_batch_size with 32 and the auto_find_batch_size will lower it in case vram overload)\n        learning_rate=2e-5, # <<< the learning rate (0.0002) for higher gpu use (2e-5) for more training stability.\n        weight_decay=0.1, # <<< Help fit the model, Default is 0.01 (used by fastai) but 0.1 works well.\n        logging_steps=135, # <<< Output the training/test loss every how many steps.\n        optim=\"paged_adamw_8bit\", # <<< the optimizer for adjusting model parameters to reduce model error in each training step.\n    ),\n    data_collator=transformers.DataCollatorForLanguageModeling(tokenizer, mlm=False), # Clean and organise the data inputs in training.   \n)","metadata":{"execution":{"iopub.status.busy":"2023-07-08T15:17:28.875116Z","iopub.execute_input":"2023-07-08T15:17:28.875473Z","iopub.status.idle":"2023-07-08T15:17:28.906315Z","shell.execute_reply.started":"2023-07-08T15:17:28.875443Z","shell.execute_reply":"2023-07-08T15:17:28.905407Z"},"trusted":true},"execution_count":39,"outputs":[]},{"cell_type":"code","source":"model.config.use_cache = False","metadata":{"execution":{"iopub.status.busy":"2023-07-08T15:17:32.335520Z","iopub.execute_input":"2023-07-08T15:17:32.335948Z","iopub.status.idle":"2023-07-08T15:17:32.342346Z","shell.execute_reply.started":"2023-07-08T15:17:32.335912Z","shell.execute_reply":"2023-07-08T15:17:32.341185Z"},"trusted":true},"execution_count":40,"outputs":[]},{"cell_type":"code","source":"##if torch.__version__ >= '2' and sys.platform != 'win32':\n  ##  model = torch.compile(model)","metadata":{"execution":{"iopub.status.busy":"2023-07-08T15:13:58.991879Z","iopub.status.idle":"2023-07-08T15:13:58.992928Z","shell.execute_reply.started":"2023-07-08T15:13:58.992679Z","shell.execute_reply":"2023-07-08T15:13:58.992703Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# while importing from peft used prepare_model_for_int8_training instead of prepare_model_for_kbit_training\n# similarly while initializing model, called method prepare_model_for_int8_training() instead of prepare_model_for_kbit_training\n# ","metadata":{"execution":{"iopub.status.busy":"2023-07-08T15:13:58.994140Z","iopub.status.idle":"2023-07-08T15:13:58.994958Z","shell.execute_reply.started":"2023-07-08T15:13:58.994703Z","shell.execute_reply":"2023-07-08T15:13:58.994727Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"trainer.train()","metadata":{"execution":{"iopub.status.busy":"2023-07-08T15:17:41.366988Z","iopub.execute_input":"2023-07-08T15:17:41.367723Z","iopub.status.idle":"2023-07-09T01:54:10.272872Z","shell.execute_reply.started":"2023-07-08T15:17:41.367688Z","shell.execute_reply":"2023-07-09T01:54:10.271515Z"},"trusted":true},"execution_count":41,"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.15.5"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20230708_151742-kg86p8h9</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/jaiswaldelhi1/huggingface/runs/kg86p8h9' target=\"_blank\">fast-mountain-9</a></strong> to <a href='https://wandb.ai/jaiswaldelhi1/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/jaiswaldelhi1/huggingface' target=\"_blank\">https://wandb.ai/jaiswaldelhi1/huggingface</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/jaiswaldelhi1/huggingface/runs/kg86p8h9' target=\"_blank\">https://wandb.ai/jaiswaldelhi1/huggingface/runs/kg86p8h9</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='1156' max='1156' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [1156/1156 10:35:21, Epoch 17/17]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>135</td>\n      <td>0.923100</td>\n    </tr>\n    <tr>\n      <td>270</td>\n      <td>0.640800</td>\n    </tr>\n    <tr>\n      <td>405</td>\n      <td>0.561900</td>\n    </tr>\n    <tr>\n      <td>540</td>\n      <td>0.492300</td>\n    </tr>\n    <tr>\n      <td>675</td>\n      <td>0.425600</td>\n    </tr>\n    <tr>\n      <td>810</td>\n      <td>0.363700</td>\n    </tr>\n    <tr>\n      <td>945</td>\n      <td>0.304000</td>\n    </tr>\n    <tr>\n      <td>1080</td>\n      <td>0.256000</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"execution_count":41,"output_type":"execute_result","data":{"text/plain":"TrainOutput(global_step=1156, training_loss=0.47833663617038397, metrics={'train_runtime': 38188.1751, 'train_samples_per_second': 0.24, 'train_steps_per_second': 0.03, 'total_flos': 1.299905701011456e+17, 'train_loss': 0.47833663617038397, 'epoch': 17.0})"},"metadata":{}}]},{"cell_type":"code","source":"wandb.finish()","metadata":{"execution":{"iopub.status.busy":"2023-07-09T01:54:15.084887Z","iopub.status.idle":"2023-07-09T01:54:15.085634Z","shell.execute_reply.started":"2023-07-09T01:54:15.085359Z","shell.execute_reply":"2023-07-09T01:54:15.085384Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.save_pretrained(OUTPUT_DIR)","metadata":{"execution":{"iopub.status.busy":"2023-07-09T01:54:15.086980Z","iopub.status.idle":"2023-07-09T01:54:15.087709Z","shell.execute_reply.started":"2023-07-09T01:54:15.087446Z","shell.execute_reply":"2023-07-09T01:54:15.087479Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.push_to_hub(\"Llama_train_sk\", use_auth_token=hf_key)","metadata":{"execution":{"iopub.status.busy":"2023-07-09T01:55:47.217431Z","iopub.execute_input":"2023-07-09T01:55:47.218356Z","iopub.status.idle":"2023-07-09T01:55:54.874612Z","shell.execute_reply.started":"2023-07-09T01:55:47.218321Z","shell.execute_reply":"2023-07-09T01:55:54.873501Z"},"trusted":true},"execution_count":46,"outputs":[{"output_type":"display_data","data":{"text/plain":"adapter_model.bin:   0%|          | 0.00/33.7M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"da301b31be17406b860a5bd2ab5d684a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Upload 1 LFS files:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9202544fe8a5442187c3a6c95308322a"}},"metadata":{}},{"execution_count":46,"output_type":"execute_result","data":{"text/plain":"CommitInfo(commit_url='https://huggingface.co/SKumari/Llama_train_sk/commit/6885f877956d5663a1434ca44519116ac7247767', commit_message='Upload model', commit_description='', oid='6885f877956d5663a1434ca44519116ac7247767', pr_url=None, pr_revision=None, pr_num=None)"},"metadata":{}}]},{"cell_type":"code","source":"#Decreased learning rate.\n#Updated attention blocks.\n#Load the model in 4bit and float16 to save vram.\n#Increased warmup ratio.","metadata":{},"execution_count":null,"outputs":[]}]}